# PyTorchæœ€æ–°ãƒ¢ãƒ‡ãƒ«ã§ãƒãƒ«ãƒã‚³ã‚¢TPUã®æœ¬æ°—ã‚’è©¦ã™

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Soliton-Analytics-Team/Colab-Multicore-TPU/blob/main/ColabMulticoreTPU.ipynb)

## 1. ã¯ã˜ã‚ã«

ç„¡æ–™ã§ä½¿ãˆã‚‹[Google Colab](https://colab.reseach.google.com)ã¯ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã®ã‚¿ã‚¤ãƒ—ã«TPUãŒé¸æŠã§ãã¾ã™ã€‚å˜ã«é¸æŠã—ãŸã ã‘ã§ä½¿ãˆã¦æ¬²ã—ã„ã¨ã“ã‚ã§ã™ãŒã€ã‚ã„ã«ããã†ã¯ãªã£ã¦ã„ã¾ã›ã‚“ã€‚ã¾ãŸã€Colabã®TPUã¯8ã‚³ã‚¢æ§‹æˆãªã®ã§ã™ãŒã€1ã‚³ã‚¢ã ã‘ã§ã‚‚ä½¿ãˆã¦ã—ã¾ã†ã®ã§ã€1ã‚³ã‚¢ã ã‘ã§æ€§èƒ½æ¯”è¼ƒã—ã¦ã€GPUã¨ã‚ã‚“ã¾ã‚Šå¤‰ã‚ã‚‰ãªã„ã¨ã—ã¦ã—ã¾ã£ã¦ã„ã‚‹è¨˜äº‹ã‚’ã¡ã‚‰ã»ã‚‰è¦‹ã‹ã‘ã¾ã™ã€‚å®Ÿéš›ã€1ã‚³ã‚¢ã ã‘ã ã¨P100ã¨åŒç¨‹åº¦ã®æ€§èƒ½ã£ã½ã„ã§ã™ã€‚ãŸã ã€Colabã®TPUã®ã„ã„ã¨ã‚ã“ã¯8ã‚³ã‚¢ã‚’ä½¿ãˆã‚‹ã“ã¨ã¨ã€TPUã«ä»˜éšã™ã‚‹ãƒ¡ãƒ¢ãƒªãŒãŸãã•ã‚“ä½¿ãˆã‚‹ã“ã¨ãªã®ã§ã€ãã‚Œã‚’ä½¿ã„ãŸã„ã€‚

ã„ã‚ã„ã‚æ¢ã—å›ã£ãŸã¨ã“ã‚ã€ç´ æ™´ã‚‰ã—ã„è¨˜äº‹ã‚’è¦‹ã¤ã‘ã¾ã—ãŸã€‚ã€Œ[è»¢ç§»å­¦ç¿’ã§CIFAR-10æ­£è§£ç‡99%ã‚’é”æˆã™ã‚‹æ–¹æ³•](https://qiita.com/T-STAR/items/de933c67b52a47f9efef)ã€ã§ã™ã€‚ã¡ã‚ƒã‚“ã¨TPUã®ãƒãƒ«ãƒã‚³ã‚¢ã‚’ä½¿ã£ã¦ã„ã‚‹ä¸Šã«ã€ãã¡ã‚“ã¨æœ€å¾Œã¾ã§æ­£è§£ç‡ã‚’ç…®è©°ã‚ã¦ã„ã¾ã™ã€‚ãŸã ã“ã®è¨˜äº‹ã¯Kerasã§å®Ÿè£…ã—ã¦ã„ã¾ã™ã€‚ã“ã‚Œã‚’PyTorchã«ã—ãŸã„ã€‚ãªãœã‹ã¨è¨€ã†ã¨ã€[PyTorch Image Models](https://github.com/rwightman/pytorch-image-models)ã§å…¬é–‹ã•ã‚Œã¦ã„ã‚‹äº‹å‰å­¦ç¿’æ¸ˆã®æœ€æ–°ãƒ¢ãƒ‡ãƒ«ã‚’è©¦ã—ãŸã„ã‹ã‚‰ã§ã™ã€‚

ã¨ã„ã†ã‚ã‘ã§ã€åŸºæœ¬çš„ã«ä¸Šè¨˜ã®è¨˜äº‹ã‚’è¸è¥²ã—ã¤ã¤ã€PyTorchã§ãƒãƒ«ãƒã‚³ã‚¢ã®TPUã‚’ä½¿ã£ã¦ã¿ãŸã®ã§ã€ã“ã“ã«å…¬é–‹ã—ã¾ã™ã€‚Colabã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ãªã®ã§ã€å…¨ã¦ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã™ã‚Œã°å‹•ä½œã—ã¾ã™ã€‚



ã¾ãšã¯ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã®è¨­å®šãŒTPUã«ãªã£ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¾ã™ã€‚ãªã£ã¦ã„ãªã‘ã‚Œã°ã€è¨­å®šã‚’å¤‰ãˆã¦ãã ã•ã„ã€‚


```python
import os
assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'
```

æ¬¡ã«Googleãƒ‰ãƒ©ã‚¤ãƒ–ã‚’ãƒã‚¦ãƒ³ãƒˆã—ã¾ã™ã€‚Colabã§ã¯æ™‚é–“ã§å®Ÿè¡Œåœæ­¢ã•ã‚Œã¦ã—ã¾ã†ã“ã¨ãŒã‚ã‚‹ã®ã§ã€é€”ä¸­ã‹ã‚‰å†é–‹ã§ãã‚‹ã‚ˆã†ã«é€”ä¸­çµæœã‚’ä¿æŒã™ã‚‹ãŸã‚ã§ã™ã€‚


```python
from google.colab import drive
drive.mount('/content/drive')
```

    Mounted at /content/drive


[PyTorch/XLA](https://github.com/pytorch/xla)ã¨ã„ã†ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ã€‚ä¸‹è¨˜ã®1.9ã¨ã„ã†æ•°å­—éƒ¨åˆ†ã¯ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚é©å®œèª¿æ•´ã—ã¦ãã ã•ã„ã€‚ä¾å­˜é–¢ä¿‚ã®ã‚¨ãƒ©ãƒ¼ãŒå‡ºã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ãŒã€ç¾æ™‚ç‚¹ã§ã¯å½±éŸ¿ãªã„ã®ã§æ°—ã«ã›ãšå…ˆã«é€²ã‚“ã§å•é¡Œã‚ã‚Šã¾ã›ã‚“ã€‚


```shell
!pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl
```

    Collecting torch-xla==1.9
      Downloading https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl (149.9 MB)
    [K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149.9 MB 20 kB/s 
    [?25hCollecting cloud-tpu-client==0.10
      Downloading cloud_tpu_client-0.10-py3-none-any.whl (7.4 kB)
      .
      .
      .


## 2. CIFAR100

ãã‚Œã§ã¯æœ€åˆã«ç”»åƒåˆ†é¡ã®å¯¾è±¡ã¨ã™ã‚‹CIFAR100ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç¢ºèªã—ã¾ã—ã‚‡ã†ã€‚ã“ã‚Œã¯torchvisionã®ä¸­ã«datasetsã¨ã—ã¦å†…è”µã•ã‚Œã¦ã„ã‚‹ã®ã§ã€ç°¡å˜ã«å–å¾—ã§ãã¾ã™ã€‚ã¡ãªã¿ã«datasets.classesã§åˆ†é¡ã®åå‰ã‚’å–å¾—ã§ãã‚‹ã®ã‚’ä»Šå›ã¯ã˜ã‚ã¦çŸ¥ã‚Šã¾ã—ãŸã€‚


```python
import matplotlib.pyplot as plt
import torchvision

datasets = torchvision.datasets.CIFAR100(root='./data', download=True)

H = 10
W = 10
fig = plt.figure(figsize=(H, W))
fig.subplots_adjust(left=0, right=1, bottom=0, top=1.0, hspace=0.4, wspace=0.4)

for k in range(H * W):
    image = datasets.data[k]
    label = datasets.targets[k]
    plt.subplot(H, W, k+1)
    plt.imshow(image)
    plt.title(datasets.classes[label], fontsize=12)
    plt.axis('off')

plt.show()
```


![1.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1646184/d37b9afc-7016-2656-d526-686be31a9cb9.png)


ç”»åƒã¯32x32ã§å°ã•ã„ã§ã™ãŒã€äººé–“ãªã‚‰è­˜åˆ¥ã§ãã¾ã™ã­ã€‚ãŸã æœ¬å½“ã«äººé–“ãŒåˆ†é¡ã™ã‚‹ã¨ãªã‚‹ã¨100å€‹ã®åˆ†é¡ã‚’è¦šãˆã‚‹ã®ãŒå¤§å¤‰ã§ã™ã€‚ä½•åä¸‡ä»¶ã‚‚åˆ†é¡ã•ã›ã‚‰ã‚ŒãŸã‚‰ã†ã£ã‹ã‚Šæ•°ï¼…ã¯é–“é•ãˆãã†ã§ã™ã€‚

## 3. ãƒ¢ãƒ‡ãƒ«

æ¤œè¨¼ã«ä½¿ã†ãƒ¢ãƒ‡ãƒ«ã¯[PyTorch Image Models](https://github.com/rwightman/pytorch-image-models)ã®ã‚‚ã®ã‚’ä½¿ã„ã¾ã™ã€‚ä»¥ä¸‹ã§äº‹å‰è¨“ç·´æ¸ˆã¿é‡ã¿ä»˜ãã®ãƒ¢ãƒ‡ãƒ«ã®ä¸€è¦§ã‚’å–å¾—ã§ãã¾ã™ã€‚


```shell
!pip install timm
import timm
timm.list_models(pretrained=False)
```

    Collecting timm
      Downloading timm-0.4.12-py3-none-any.whl (376 kB)
    [K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 376 kB 5.3 MB/s 
    [?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.10.0+cu102)
    Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.9.0+cu102)
    .
    .
    .
     'tf_efficientnetv2_l',
     'tf_efficientnetv2_l_in21ft1k',
     'tf_efficientnetv2_l_in21k',
     'tf_efficientnetv2_m',
     'tf_efficientnetv2_m_in21ft1k',
     'tf_efficientnetv2_m_in21k',
     'tf_efficientnetv2_s',
     .
     .
     .

'tf_efficientnetv2_l_in21ft1k'ã®æ–‡å­—ãŒè¦‹ãˆã¾ã™ã­ã€‚ã“ã‚Œã¯ImageNet-21Kã§äº‹å‰è¨“ç·´ã•ã‚ŒãŸé‡ã¿ã‚’æŒã£ãŸefficientnetv2ã¨æ€ã‚ã‚Œã¾ã™ã®ã§ã€ä»Šå›ã¯ã“ã‚Œã‚’ä½¿ã„ã¾ã—ã‚‡ã†ã€‚


```python
model_name = 'tf_efficientnetv2_l_in21ft1k'
```

## 4. Transform

å…¥åŠ›ç”»åƒã«å¯¾ã™ã‚‹å‰å‡¦ç†ã¯ã€ä½¿ç”¨ã™ã‚‹äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã«åˆã‚ã›ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚timmã§ã¯ä»¥ä¸‹ã®æ§˜ã«ã™ã‚‹ã¨ãã®å‰å‡¦ç†ã‚’å–å¾—ã§ãã¾ã™ã€‚


```python
from timm.data import resolve_data_config
from timm.data.transforms_factory import create_transform
import warnings
warnings.filterwarnings('ignore')

config = resolve_data_config({}, model=model_name)
print('config\n', config)
base_transform = create_transform(**config)
print('\nbase_transform\n', base_transform)
```

    config
     {'input_size': (3, 224, 224), 'interpolation': 'bicubic', 'mean': (0.485, 0.456, 0.406), 'std': (0.229, 0.224, 0.225), 'crop_pct': 0.875}
    
    base_transform
     Compose(
        Resize(size=256, interpolation=bicubic, max_size=None, antialias=None)
        CenterCrop(size=(224, 224))
        ToTensor()
        Normalize(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))
    )


ã¨ã„ã†ã“ã¨ã ã£ãŸã‚“ã§ã™ãŒã€ã©ã†ã‚„ã‚‰æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã¯ãƒ‡ãƒ¼ã‚¿ãŒæ›´æ–°ã•ã‚Œã¦ã„ãªã„ã‚ˆã†ã§ã™ã€‚ä»Šå›ã¯ã“ã®ã¾ã¾é€²ã‚ã¾ã™ãŒã€å…¥åŠ›ã‚µã‚¤ã‚ºã‚’å¤‰æ›´ã—ãŸã„å ´åˆã¯ä¸‹è¨˜ã®ã‚³ãƒ¡ãƒ³ãƒˆã‚’å¤–ã—ã¦ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚


```python
# from torchvision import transforms
# from torchvision.transforms.functional import InterpolationMode
# input_size = (280, 280)
# crop_pct = 0.875

# base_transform = transforms.Compose([
#     transforms.Resize(size=int(input_size[0]/crop_pct),
#                       interpolation=InterpolationMode.BICUBIC),
#     transforms.CenterCrop(size=input_size),
#     transforms.ToTensor(),
#     transforms.Normalize(mean=[0.4850, 0.4560, 0.4060],
#                          std=[0.2290, 0.2240, 0.2250])
# ])
# print(base_transform)
```

ä»¶ã®è¨˜äº‹ã§ã¯
> ã“ã“ã§ã¯ã€ã‚ˆãã‚ã‚‹å·¦å³ãƒ•ãƒªãƒƒãƒ—ã¨ä¸Šä¸‹å·¦å³ã®Shiftã«åŠ ãˆã¦ã€Cutoutã®ã‚µã‚¤ã‚ºã‚’0.4ã¨ã—ã¦ï¼’å›ã¨ã€Saturation/Contrastã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«å¤‰æ›´ã™ã‚‹å‡¦ç†ã‚’å…¥ã‚ŒãŸã€‚

ã¨æ›¸ã„ã¦ã‚ã‚‹ã®ã§æ¦‚ã­åŒæ§˜ã®å‡¦ç†ã«ãªã‚‹ã‚ˆã†ã«ã—ã¾ã—ãŸã€‚æ³¨æ„ç‚¹ã¨ã—ã¦ã€torchvision.transformsã®RandomErasing()ã¯å‡¦ç†å¯¾è±¡ãŒãƒ†ãƒ³ã‚½ãƒ«ãªã®ã§ã€base_transformã®å¾Œã«æŒ¿å…¥ã—ãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚

torchvision.transformsã§ã©ã‚“ãªã‚‚ã®ãŒä½¿ãˆã‚‹ã®ã‹ã¯ã€Œ[Pytorch â€“ torchvision ã§ä½¿ãˆã‚‹ Transform ã¾ã¨ã‚](https://pystyle.info/pytorch-list-of-transforms/)ã€ãŒåˆ†ã‹ã‚Šã‚„ã™ã„ã®ã§å‚è€ƒã«ã—ã¦ãã ã•ã„ã€‚


```python
from torchvision import transforms
train_transform = transforms.Compose([transforms.RandomHorizontalFlip(),
                                        transforms.RandomCrop(32, padding=4),
                                        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.5)]
                                       + base_transform.transforms
                                       + [transforms.RandomErasing(), transforms.RandomErasing()])
```

## 5. DataSet

ç„¼ãå…¥ã‚Œç”¨ã€å­¦ç¿’ç”¨ã€è©•ä¾¡ç”¨ã®ï¼“ã¤ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œã‚Šã¾ã™ã€‚


```python
from torchvision.datasets import CIFAR100

burn_dataset = CIFAR100(root='./data', train=True, transform=base_transform, download=True)
train_dataset = CIFAR100(root='./data', train=True, transform=train_transform, download=True)
test_dataset = CIFAR100(root='./data', train=False, transform=base_transform, download=True)

print(len(train_dataset), len(test_dataset))
```

    Files already downloaded and verified
    Files already downloaded and verified
    Files already downloaded and verified
    50000 10000


## 5.5. ãƒãƒ«ãƒã‚³ã‚¢å‹•ä½œã®ç¢ºèª

ã›ã£ã‹ããªã®ã§ãƒãƒ«ãƒã‚³ã‚¢ã§å‹•ä½œã™ã‚‹æ§˜å­ã‚’ç¢ºèªã—ã¦ã¿ãŸã„ã¨æ€ã„ã¾ã™ã€‚æœ¬å½“ã¯è¨˜äº‹ã®æµã‚Œã«æ²¿ã£ã¦å®Ÿéš›ã«è¨“ç·´ã—ãªãŒã‚‰ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã‚’8æœ¬è¡¨ç¤ºã•ã›ãŸã‹ã£ãŸã®ã§ã™ãŒã€è¡¨ç¤ºã•ã›ã‚‹ã¨é€”ä¸­ã§å‡¦ç†ãŒæ­¢ã¾ã£ã¦ã—ã¾ã†ã®ã§æ–­å¿µã—ã¾ã—ãŸã€‚
ã“ã®ã€Œ5.5.ã€€ãƒãƒ«ãƒã‚³ã‚¢å‹•ä½œã®ç¢ºèªã€å†…ã®ã‚³ãƒ¼ãƒ‰ã¯å¾Œã®å‡¦ç†ã«ã¯å¿…è¦ãªã„ã®ã§ã€ç¢ºèªã™ã‚‹å¿…è¦ã®ãªã„æ–¹ã¯é£›ã°ã—ã¦ã—ã¾ã£ã¦æ§‹ã„ã¾ã›ã‚“ã€‚

ä¸€æ°—ã«å…¨ã¦ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã™ã‚‹ã¨ãã«å®Ÿè¡Œã—ãŸããªã„ã®ã§ã€ã‚³ãƒ¼ãƒ‰ã¯å…¨ã¦ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã—ã¦ãŠãã¾ã™ã€‚
å®Ÿè¡Œã™ã‚‹ã¨ã€ä¸‹ã®ç”»åƒã®ã‚ˆã†ã«ã‚³ã‚¢æ•°ã¨åŒæ•°ã®ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚

![2.png]()

ãªãŠã€æœ¬æ¥å®Ÿè¡Œã™ã‚‹ã‚³ãƒ¼ãƒ‰ã‚’ç¢ºèªç”¨ã«åˆ‡ã‚Šè©°ã‚ã¦ç·¨é›†ã—ãŸã®ã§ã€ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã¯é€”ä¸­ã§ã‚¨ãƒ©ãƒ¼ã«ãªã£ã¦æ­¢ã¾ã‚Šã¾ã™ã€‚
ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã§ç¢ºèªã§ããŸã‚‰ã€å‡¦ç†ã‚’ä¸­æ­¢ã—ã¦æ¬¡ã®6.ã«é€²ã‚“ã§ãã ã•ã„ã€‚


```python
# import time
# import torch
# import torch_xla.core.xla_model as xm
# from tqdm.notebook import tqdm

# def train_fn(title, model, dataloader, optimizer, criterion, device):

#     running_loss = 0
#     total = 0
#     correct = 0

#     model.train()

#     dataloader = tqdm(dataloader)
#     dataloader.set_description(title)
#     for images, labels in dataloader:
#         images = images.to(device)
#         labels = labels.to(device)
#         optimizer.zero_grad()
#         lr = optimizer.param_groups[0]['lr']

#         outputs = model(images)
#         loss = criterion(outputs, labels)
#         loss.backward()
#         xm.optimizer_step(optimizer)

#         running_loss += loss.item()
#         _, predicted = torch.max(outputs.data, 1)
#         total += labels.size(0)
#         correct += (predicted == labels).float().sum().item()

#         dataloader.set_postfix(acc=correct/total, loss=running_loss/total, lr=lr)

#     return running_loss / total, correct / total
```


```shell
# !pip install 'git+https://github.com/katsura-jp/pytorch-cosine-annealing-with-warmup'
```


```python
# import os
# from torch import hub
# import torch_xla.distributed.parallel_loader as pl
# from cosine_annealing_warmup import CosineAnnealingWarmupRestarts
# import torch_xla.utils.serialization as xser
# from torch.utils.tensorboard import SummaryWriter

# def map_fn(index, flags):
#     EPOCHS = flags['num_epochs']
#     BATCH_SIZE = flags['batch_size']
#     BURN_STEPS = flags['burn_steps']
#     torch.manual_seed(flags['seed'])
            
#     train_sampler = torch.utils.data.distributed.DistributedSampler(
#           train_dataset,
#           num_replicas=xm.xrt_world_size(),
#           rank=xm.get_ordinal(),
#           shuffle=True)

#     log_writer = None
#     train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=train_sampler, num_workers=flags['num_workers'])
#     burn_dataloader = torch.utils.data.DataLoader(burn_dataset, batch_size=BATCH_SIZE, sampler=train_sampler, num_workers=flags['num_workers'])
#     if xm.is_master_ordinal():
#         valid_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, num_workers=flags['num_workers'])

#     start_epoch = -1
#     if not xm.is_master_ordinal():
#         xm.rendezvous('download_only_once')
#     model = hub.load('rwightman/pytorch-image-models:master', model_name, pretrained=(start_epoch<0))
#     if start_epoch >= 0:
#         model.load_state_dict(state_dict['model'])
#     if xm.is_master_ordinal():
#         xm.rendezvous('download_only_once')
#     head = model.get_classifier()
#     head.out_features = 100

#     device = xm.xla_device()
#     model = model.to(device)
#     criterion = torch.nn.CrossEntropyLoss()

#     # Burn
#     if start_epoch < BURN_STEPS:
#         for param in model.parameters():
#             param.require_grad = False
#         for param in head.parameters():
#             param.require_grad = True
#         optimizer = torch.optim.SGD(head.parameters(), lr=flags['burn_lr'], momentum=0.9)
#         scheduler = CosineAnnealingWarmupRestarts(
#             optimizer,
#             first_cycle_steps=BURN_STEPS,
#             max_lr=flags['burn_lr'],
#             min_lr=flags['min_lr'],
#             warmup_steps=0)
#         for epoch in range(BURN_STEPS):
#             scheduler.step(epoch)
#             loss, acc = train_fn(f'Burn {epoch}',
#                                 model,
#                                 dataloader=pl.MpDeviceLoader(train_dataloader, device), 
#                                 optimizer=optimizer, 
#                                 criterion=criterion,
#                                 device=device)
#             if xm.is_master_ordinal():
#                 if log_writer:
#                     log_writer.add_scalar('loss', loss, epoch)
#                     log_writer.add_scalar('acc', acc, epoch)
#                     log_writer.flush()
#         if xm.is_master_ordinal():
#             loss, acc = valid_fn(f'Valid {BURN_STEPS}',
#                                 model,
#                                 dataloader=valid_dataloader, 
#                                 criterion=criterion, 
#                                 device=device)
#             if log_writer:
#                 log_writer.add_scalar('val_loss', loss, BURN_STEPS)
#                 log_writer.add_scalar('val_acc', acc, BURN_STEPS)
#                 log_writer.flush()
```


```python
# import torch_xla.distributed.xla_multiprocessing as xmp

# flags={}
# flags['batch_size'] = 64
# flags['num_workers'] = 8
# flags['burn_steps'] = 10
# flags['warmup_steps'] = 5
# flags['num_epochs'] = 1
# flags['burn_lr'] = 0.1
# flags['max_lr'] = 0.01
# flags['min_lr'] = 0.0005
# flags['seed'] = 1234
# xmp.spawn(map_fn, args=(flags,), nprocs=8, start_method='fork')
```

## 6. å­¦ç¿’ã¨è©•ä¾¡ã®é–¢æ•°

å­¦ç¿’ç”¨ã¨è©•ä¾¡ç”¨ã®é–¢æ•°ã‚’å®šç¾©ã—ã¾ã™ã€‚é€šå¸¸ã®PyTorchã®ã‚‚ã®ã¨ã»ã¼åŒã˜ã§ã™ãŒã€å­¦ç¿’ç”¨ã¯åˆ†æ•£å‡¦ç†ã™ã‚‹ã®ã§ã€ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼ã®ã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡ŒãŒxm.optimizer_step(optimizer)ã«ãªã£ã¦ã„ã¾ã™ã€‚ã“ã“ã§åˆ†æ•£ã•ã‚ŒãŸå„ãƒ¢ãƒ‡ãƒ«ã®åŒæœŸã‚’ã¨ã£ã¦ã„ã¾ã™ã€‚


```python
import time
import torch
import torch_xla.core.xla_model as xm
from tqdm import tqdm

def train_fn(title, model, dataloader, optimizer, criterion, device):

    running_loss = 0
    total = 0
    correct = 0

    model.train()
    if xm.is_master_ordinal():
        dataloader = tqdm(dataloader)
        dataloader.set_description(title)
    for images, labels in dataloader:
        images = images.to(device)
        labels = labels.to(device)
        optimizer.zero_grad()
        lr = optimizer.param_groups[0]['lr']

        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        xm.optimizer_step(optimizer)

        running_loss += loss.item()
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).float().sum().item()

        if xm.is_master_ordinal():
            dataloader.set_postfix(acc=correct/total, loss=running_loss/total, lr=lr)

    return running_loss / total, correct / total



def valid_fn(title, model, dataloader, criterion, device):

    running_loss = 0
    total = 0
    correct = 0

    model.eval()
    dataloader = tqdm(dataloader)
    dataloader.set_description(title)
    with torch.no_grad():
        for images, labels in dataloader:
            images = images.to(device)
            labels = labels.to(device)

            outputs = model(images)

            loss = criterion(outputs, labels)

            running_loss += loss.item()

            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
            dataloader.set_postfix(val_acc=correct/total, val_loss=running_loss/total)

    return running_loss / total, correct / total

```

    WARNING:root:Waiting for TPU to be start up with version pytorch-1.9...
    WARNING:root:Waiting for TPU to be start up with version pytorch-1.9...
    WARNING:root:TPU has started up successfully with version pytorch-1.9


## 7. å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©

å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ã¯ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—ä»˜ãã‚³ã‚µã‚¤ãƒ³ã‚¢ãƒ‹ãƒ¼ãƒªãƒ³ã‚°ã‚’ä½¿ã„ãŸã„ã®ã§ã€ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ã€‚


```shell
!pip install 'git+https://github.com/katsura-jp/pytorch-cosine-annealing-with-warmup'
```

    Collecting git+https://github.com/katsura-jp/pytorch-cosine-annealing-with-warmup
      Cloning https://github.com/katsura-jp/pytorch-cosine-annealing-with-warmup to /tmp/pip-req-build-6dvhbdr1
      Running command git clone -q https://github.com/katsura-jp/pytorch-cosine-annealing-with-warmup /tmp/pip-req-build-6dvhbdr1
    Building wheels for collected packages: cosine-annealing-warmup
      Building wheel for cosine-annealing-warmup (setup.py) ... [?25l[?25hdone
      Created wheel for cosine-annealing-warmup: filename=cosine_annealing_warmup-2.0-py3-none-any.whl size=3334 sha256=17d45687d5b471438001d8037c7d14f5a939f3a29a9e2422c43ac1f25df3965b
      Stored in directory: /tmp/pip-ephem-wheel-cache-u4s8g7rm/wheels/6c/b9/45/0fa58a1711c535236d946bbeff05d366eaf6818faed404625e
    Successfully built cosine-annealing-warmup
    Installing collected packages: cosine-annealing-warmup
    Successfully installed cosine-annealing-warmup-2.0


## 8. è¨“ç·´é–¢æ•°

æ¬¡ã«è¨“ç·´ç”¨ã®é–¢æ•°ã‚’å®šç¾©ã—ã¾ã™ã€‚é€”ä¸­çµæœã‚’ä¿å­˜ã™ã‚‹ã‚ˆã†ã«ãªã£ã¦ã„ã‚‹ã®ã§ã€å®Ÿè¡ŒãŒä¸­æ–­ã•ã‚ŒãŸã‚‰å†å®Ÿè¡Œã™ã‚‹ã“ã¨ã§å†é–‹ã§ãã¾ã™ã€‚


```python
import os
from torch import hub
import torch_xla.distributed.parallel_loader as pl
from cosine_annealing_warmup import CosineAnnealingWarmupRestarts
import torch_xla.utils.serialization as xser
from torch.utils.tensorboard import SummaryWriter

def map_fn(index, flags):
    EPOCHS = flags['num_epochs']
    BATCH_SIZE = flags['batch_size']
    BURN_STEPS = flags['burn_steps']
    torch.manual_seed(flags['seed'])
            
    train_sampler = torch.utils.data.distributed.DistributedSampler(
          train_dataset,
          num_replicas=xm.xrt_world_size(),
          rank=xm.get_ordinal(),
          shuffle=True)

    log_writer = None
    if xm.is_master_ordinal():
        log_writer = SummaryWriter(log_dir=f"/content/drive/MyDrive/log/{model_name}_cifar100")
    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=train_sampler, num_workers=flags['num_workers'])
    burn_dataloader = torch.utils.data.DataLoader(burn_dataset, batch_size=BATCH_SIZE, sampler=train_sampler, num_workers=flags['num_workers'])
    if xm.is_master_ordinal():
        valid_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, num_workers=flags['num_workers'])

    start_epoch = -1
    load_file = f'/content/drive/MyDrive/{model_name}_cifar100.pt'
    save_file = f'/content/drive/MyDrive/{model_name}_cifar100.pt'
    if os.path.exists(load_file):
        state_dict = xser.load(load_file)
        start_epoch = state_dict['epoch']
    if not xm.is_master_ordinal():
        xm.rendezvous('download_only_once')
    model = hub.load('rwightman/pytorch-image-models:master', model_name, pretrained=(start_epoch<0))
    if start_epoch >= 0:
        model.load_state_dict(state_dict['model'])
    if xm.is_master_ordinal():
        xm.rendezvous('download_only_once')
    head = model.get_classifier()
    head.out_features = 100

    device = xm.xla_device()
    model = model.to(device)
    criterion = torch.nn.CrossEntropyLoss()

    # Burn
    if start_epoch < BURN_STEPS:
        for param in model.parameters():
            param.require_grad = False
        for param in head.parameters():
            param.require_grad = True
        optimizer = torch.optim.SGD(head.parameters(), lr=flags['burn_lr'], momentum=0.9)
        scheduler = CosineAnnealingWarmupRestarts(
            optimizer,
            first_cycle_steps=BURN_STEPS,
            max_lr=flags['burn_lr'],
            min_lr=flags['min_lr'],
            warmup_steps=0)
        for epoch in range(BURN_STEPS):
            scheduler.step(epoch)
            loss, acc = train_fn(f'Burn {epoch}',
                                model,
                                dataloader=pl.MpDeviceLoader(train_dataloader, device), 
                                optimizer=optimizer, 
                                criterion=criterion,
                                device=device)
            if xm.is_master_ordinal():
                if log_writer:
                    log_writer.add_scalar('loss', loss, epoch)
                    log_writer.add_scalar('acc', acc, epoch)
                    log_writer.flush()
        if xm.is_master_ordinal():
            loss, acc = valid_fn(f'Valid {BURN_STEPS}',
                                model,
                                dataloader=valid_dataloader, 
                                criterion=criterion, 
                                device=device)
            if log_writer:
                log_writer.add_scalar('val_loss', loss, BURN_STEPS)
                log_writer.add_scalar('val_acc', acc, BURN_STEPS)
                log_writer.flush()

    # Train
    for param in model.parameters():
        param.require_grad = True  
    optimizer = torch.optim.SGD(model.parameters(), lr=flags['max_lr'], momentum=0.9)
    scheduler = CosineAnnealingWarmupRestarts(
        optimizer,
        first_cycle_steps=EPOCHS + 1,
        max_lr=flags['max_lr'],
        min_lr=flags['min_lr'],
        warmup_steps=flags['warmup_steps'])
    for epoch in range(start_epoch + 1, EPOCHS + 1):
        scheduler.step(epoch)
        loss, acc = train_fn(f'Train {epoch+BURN_STEPS}',
                            model,
                            dataloader=pl.MpDeviceLoader(train_dataloader, device), 
                            optimizer=optimizer, 
                            criterion=criterion,
                            device=device)
        if xm.is_master_ordinal():
            if log_writer:
                log_writer.add_scalar('loss', loss, epoch + BURN_STEPS)
                log_writer.add_scalar('acc', acc, epoch + BURN_STEPS)
                log_writer.flush()

        if os.path.exists(save_file) and xm.is_master_ordinal():
            os.rename(save_file, save_file + '.bak')
        xm.save({'epoch':epoch,
                 'model':model.state_dict(),
                 'flags':flags,
                 },
                 save_file)

        if epoch % 5 == 0 and epoch > 0:
            if xm.is_master_ordinal():
                loss, acc = valid_fn(f'Valid {epoch+BURN_STEPS}',
                                    model,
                                    dataloader=valid_dataloader, 
                                    criterion=criterion, 
                                    device=device)
                if log_writer:
                    log_writer.add_scalar('val_loss', loss, epoch + BURN_STEPS)
                    log_writer.add_scalar('val_acc', acc, epoch + BURN_STEPS)
                    log_writer.flush()


    if log_writer:
        log_writer.close()

```

## 9. è¨“ç·´

è¨“ç·´ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚æœ€å¾Œã®è¡Œã®ã€Œnprocs=8ã€ãŒã‚³ã‚¢æ•°ã§ã™ã€‚
epochæ•°ã‚’100å›ã«ã—ã¦ã„ã¾ã™ãŒåŠæ—¥ãã‚‰ã„ã‹ã‹ã‚Šã¾ã™ã€‚Proã§ãªã„Colabã§è©¦ã™å ´åˆã¯é€”ä¸­ã§åœæ­¢ã—ã¦ã—ã¾ã†ã®ã§ã€ä½•åº¦ã‹å®Ÿè¡Œã—ç›´ã™å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚
é€”ä¸­çµŒéã¯ä¿å­˜ã—ã¦ã‚ã‚‹ã®ã§ã€åœæ­¢ã—ã¦ã—ã¾ã£ãŸã‚‰ãƒªã‚»ãƒƒãƒˆã—ã¦å…¨ã¦ã®ã‚»ãƒ«ã‚’å†å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚ç¶šãã‹ã‚‰å†é–‹ã•ã‚Œã¾ã™ã€‚

```python
import torch_xla.distributed.xla_multiprocessing as xmp

flags={}
flags['batch_size'] = 64
flags['num_workers'] = 8
flags['burn_steps'] = 10
flags['warmup_steps'] = 5
flags['num_epochs'] = 100
flags['burn_lr'] = 0.1
flags['max_lr'] = 0.01
flags['min_lr'] = 0.0005
flags['seed'] = 1234
xmp.spawn(map_fn, args=(flags,), nprocs=8, start_method='fork')
```

    Downloading: "https://github.com/rwightman/pytorch-image-models/archive/master.zip" to /root/.cache/torch/hub/master.zip
    Using cache found in /root/.cache/torch/hub/rwightman_pytorch-image-models_master
    Using cache found in /root/.cache/torch/hub/rwightman_pytorch-image-models_master
    Using cache found in /root/.cache/torch/hub/rwightman_pytorch-image-models_master
    Using cache found in /root/.cache/torch/hub/rwightman_pytorch-image-models_master
    Using cache found in /root/.cache/torch/hub/rwightman_pytorch-image-models_master
    Using cache found in /root/.cache/torch/hub/rwightman_pytorch-image-models_master
    Using cache found in /root/.cache/torch/hub/rwightman_pytorch-image-models_master
    Train 83: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 98/98 [13:16<00:00,  8.13s/it, acc=1, loss=3.9e-5, lr=0.00236]
    .
    .
    .
    Train 109: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 98/98 [04:39<00:00,  2.85s/it, acc=0.999, loss=9.45e-5, lr=0.00051]
    Train 110: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 98/98 [04:39<00:00,  2.85s/it, acc=1, loss=5.12e-5, lr=0.000503]
    Valid 110: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [02:00<00:00,  1.30it/s, val_acc=0.912, val_loss=0.00554]


## 10. çµæœè¡¨ç¤º



```shell
%reload_ext tensorboard
%tensorboard --logdir /content/drive/MyDrive/log
```
![3.png]()


![4.png]()
